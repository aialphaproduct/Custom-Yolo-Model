import streamlit as st
import numpy as np
import cv2
import tempfile
import os
import time
import gdown  # Th∆∞ vi·ªán t·∫£i file t·ª´ Google Drive

# --- T·∫£i yolov3.weights t·ª´ Google Drive n·∫øu ch∆∞a c√≥ ---
def download_weights():
    file_id = "10ygsxRHye1DNgpErQZ6NghVIPhat6-UO"  # ID c·ªßa file tr√™n Google Drive
    output_path = "model/yolov3.weights"

    if not os.path.exists(output_path):
        st.info("üì• ƒêang t·∫£i yolov3.weights t·ª´ Google Drive...")
        file_url = f"https://drive.google.com/uc?id={file_id}"
        gdown.download(file_url, output_path, quiet=False)
        st.success("‚úÖ ƒê√£ t·∫£i xong yolov3.weights!")
    else:
        st.info("‚úîÔ∏è File yolov3.weights ƒë√£ c√≥ s·∫µn.")

# G·ªçi h√†m t·∫£i file tr∆∞·ªõc khi load m√¥ h√¨nh
download_weights()

# --- Load YOLO Model ---
@st.cache_resource
def load_yolo():
    try:
        model = cv2.dnn.readNetFromDarknet("model/yolov3.cfg", "model/yolov3.weights")
        layer_names = model.getLayerNames()
        output_layers = [layer_names[i - 1] for i in model.getUnconnectedOutLayers().flatten()]
        return model, output_layers
    except Exception as e:
        st.error(f"üö® L·ªói khi t·∫£i m√¥ h√¨nh YOLO: {e}")
        return None, None

yolo_model, yolo_output_layers = load_yolo()

# --- Class Labels ---
class_labels = ["person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
                "trafficlight", "firehydrant", "stopsign", "parkingmeter", "bench", "bird", "cat",
                "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
                "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sportsball",
                "kite", "baseballbat", "baseballglove", "skateboard", "surfboard", "tennisracket",
                "bottle", "wineglass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
                "sandwich", "orange", "broccoli", "carrot", "hotdog", "pizza", "donut", "cake", "chair",
                "sofa", "pottedplant", "bed", "diningtable", "toilet", "tvmonitor", "laptop", "mouse",
                "remote", "keyboard", "cellphone", "microwave", "oven", "toaster", "sink", "refrigerator",
                "book", "clock", "vase", "scissors", "teddybear", "hairdrier", "toothbrush"]

# M√†u cho bounding boxes
np.random.seed(42)
colors = np.random.randint(0, 255, size=(len(class_labels), 3), dtype="uint8")

# --- UI Streamlit ---
st.title("üñºÔ∏è YOLO Object Detection")
st.write("T·∫£i ·∫£nh l√™n ƒë·ªÉ nh·∫≠n di·ªán ƒë·ªëi t∆∞·ª£ng b·∫±ng YOLOv3.")

uploaded_file = st.file_uploader("üì§ Ch·ªçn ·∫£nh...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None and yolo_model:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".jpg")
    tfile.write(uploaded_file.read())
    image_path = tfile.name

    with open(image_path, "rb") as f:
        img_array = np.asarray(bytearray(f.read()), dtype=np.uint8)
        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)

    img_height, img_width = img.shape[:2]
    img_blob = cv2.dnn.blobFromImage(img, 0.003922, (416, 416), swapRB=True, crop=False)
    yolo_model.setInput(img_blob)
    detection_layers = yolo_model.forward(yolo_output_layers)

    detected_objects = {}

    # L∆∞u c√°c bounding boxes theo class_id
    for layer in detection_layers:
        for detection in layer:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:
                box = detection[:4] * np.array([img_width, img_height, img_width, img_height])
                (centerX, centerY, width, height) = box.astype("int")
                startX = int(centerX - (width / 2))
                startY = int(centerY - (height / 2))
                endX = startX + width
                endY = startY + height

                # N·∫øu class_id ch∆∞a c√≥ trong dict, kh·ªüi t·∫°o danh s√°ch m·ªõi
                if class_id not in detected_objects:
                    detected_objects[class_id] = []

                # L∆∞u bounding box v√†o danh s√°ch t∆∞∆°ng ·ª©ng v·ªõi class_id
                detected_objects[class_id].append({
                    "box": (startX, startY, endX, endY),
                    "confidence": confidence,
                    "center": (centerX, centerY)
                })

    # L·ªçc bounding box c√≥ confidence cao nh·∫•t cho t·ª´ng ƒë·ªëi t∆∞·ª£ng ri√™ng l·∫ª
    final_objects = []
    for class_id, objects in detected_objects.items():
        # S·∫Øp x·∫øp bounding boxes theo confidence gi·∫£m d·∫ßn
        objects = sorted(objects, key=lambda x: x["confidence"], reverse=True)

        # Nh√≥m bounding boxes theo v·ªã tr√≠ g·∫ßn nhau
        grouped_objects = []
        for obj in objects:
            centerX, centerY = obj["center"]

            # Ki·ªÉm tra xem c√≥ ƒë·ªëi t∆∞·ª£ng n√†o trong nh√≥m g·∫ßn v·ªõi v·ªã tr√≠ n√†y kh√¥ng
            found = False
            for group in grouped_objects:
                existing_centerX, existing_centerY = group[0]["center"]
                distance = np.sqrt((centerX - existing_centerX) ** 2 + (centerY - existing_centerY) ** 2)

                if distance < 50:  # Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh c√°c ƒë·ªëi t∆∞·ª£ng gi·ªëng nhau
                    found = True
                    break

            # N·∫øu ch∆∞a c√≥ trong nh√≥m, th√™m v√†o danh s√°ch
            if not found:
                grouped_objects.append([obj])

        # Ch·ªçn bounding box c√≥ confidence cao nh·∫•t t·ª´ m·ªói nh√≥m
        for group in grouped_objects:
            best_object = max(group, key=lambda x: x["confidence"])
            final_objects.append(best_object)

    # V·∫Ω bounding boxes l√™n ·∫£nh
    for obj in final_objects:
        (startX, startY, endX, endY) = obj["box"]
        confidence = obj["confidence"]
        class_id = next(key for key, val in detected_objects.items() if obj in val)  # L·∫•y class_id
        color = [int(c) for c in colors[class_id]]
        label = f"{class_labels[class_id]}: {confidence:.2f}"

        cv2.rectangle(img, (startX, startY), (endX, endY), color, 2)
        cv2.putText(img, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    st.image(img_rgb, caption="üìç K·∫øt qu·∫£ nh·∫≠n di·ªán", use_column_width=True)

    # X√≥a file t·∫°m th·ªùi sau khi hi·ªÉn th·ªã
    for _ in range(3):
        try:
            if os.path.exists(image_path):
                os.remove(image_path)
            break
        except PermissionError:
            time.sleep(2)
